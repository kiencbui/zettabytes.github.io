<!DOCTYPE html>
<html lang="en-us">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>False Sharing in CPU | Zettabytes</title>
  <link rel="stylesheet" href="/css/style.css" />
  <link rel="stylesheet" href="/css/fonts.css" />
  <script defer src="https://cloud.umami.is/script.js" data-website-id="9b8e8592-49c0-46c9-8bce-18029754be67"></script>
  
</head>

<body>
  <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr />
  </nav>
<div class="article-meta">
<h1><span class="title">False Sharing in CPU</span></h1>

<h2 class="date">2025/08/16</h2>
</div>

<main>
<p>False sharing is a performance problem that happens when multiple CPU cores try to work with data that lives in the same cache line, even though they&rsquo;re actually working on different pieces of data.</p>
<h2 id="what-is-a-cache-line">What is a Cache Line?</h2>
<p>To understand false sharing, we first need to know about cache lines. When a CPU reads data from memory, it doesn&rsquo;t just read one byte at a time. Instead, it reads a whole chunk of data called a cache line, which is typically 64 bytes on modern processors.</p>
<p>Think of it like this: if you want to read one page from a book, you take the entire book from the shelf, not just that single page.</p>
<h2 id="how-false-sharing-happens">How False Sharing Happens</h2>
<p>Let&rsquo;s say we have two variables sitting next to each other in memory:</p>
<ul>
<li>Variable A (used by Core 1)</li>
<li>Variable B (used by Core 2)</li>
</ul>
<p>If these variables are in the same cache line, here&rsquo;s what happens:</p>
<ol>
<li>Core 1 reads Variable A → The entire cache line gets copied to Core 1&rsquo;s cache</li>
<li>Core 2 reads Variable B → The same cache line gets copied to Core 2&rsquo;s cache</li>
<li>Core 1 modifies Variable A → Core 2&rsquo;s cache line becomes invalid</li>
<li>Core 2 modifies Variable B → Core 1&rsquo;s cache line becomes invalid</li>
</ol>
<p>Even though Core 1 and Core 2 are working on completely different data, they keep invalidating each other&rsquo;s cache. This causes a lot of unnecessary communication between cores and slows down performance.</p>
<h2 id="a-simple-example">A Simple Example</h2>
<p>Here&rsquo;s a Go example that demonstrates false sharing:</p>
<pre><code class="language-go">package main

import (
	&quot;fmt&quot;
	&quot;sync&quot;
)

func main() {
	wg := sync.WaitGroup{}
    wg.Add(2)

    var a, b int

    go func() {
        for i := 0; i &lt; 1000000; i++ {
            a++
        }
        wg.Done()
    }()

    go func() {
        for i := 0; i &lt; 1000000; i++ {
            b++
        }
        wg.Done()
    }()

    wg.Wait()
    fmt.Println(a, b)
}
</code></pre>
<p>In this example, variables <code>a</code> and <code>b</code> might be located in the same cache line, leading to false sharing when two goroutines perform increment operations simultaneously.</p>
<h2 id="how-to-avoid-false-sharing">How to Avoid False Sharing</h2>
<h3 id="1-cache-line-padding">1. Cache Line Padding</h3>
<p>A common way to avoid false sharing is to add padding to ensure variables don&rsquo;t share the same cache line:</p>
<pre><code class="language-go">type PaddedCounter struct {
    value int64
    _     [56]byte // padding to ensure separate cache lines (64 - 8 = 56 bytes)
}

func avoidFalseSharing() {
    wg := sync.WaitGroup{}
    wg.Add(2)

    var counters [2]PaddedCounter

    go func() {
        for i := 0; i &lt; 1000000; i++ {
            counters[0].value++
        }
        wg.Done()
    }()

    go func() {
        for i := 0; i &lt; 1000000; i++ {
            counters[1].value++
        }
        wg.Done()
    }()

    wg.Wait()
    fmt.Println(counters[0].value, counters[1].value)
}
</code></pre>
<h3 id="2-using-local-variables">2. Using Local Variables</h3>
<p>Instead of operating directly on shared memory, we can use local variables and only update shared memory once at the end:</p>
<pre><code class="language-go">func useLocalVariables() {
    wg := sync.WaitGroup{}
    wg.Add(2)

    var a, b int64

    go func() {
        localCounter := int64(0)
        for i := 0; i &lt; 1000000; i++ {
            localCounter++
        }
        atomic.AddInt64(&amp;a, localCounter)
        wg.Done()
    }()

    go func() {
        localCounter := int64(0)
        for i := 0; i &lt; 1000000; i++ {
            localCounter++
        }
        atomic.AddInt64(&amp;b, localCounter)
        wg.Done()
    }()

    wg.Wait()
    fmt.Println(a, b)
}
</code></pre>
<h2 id="performance-comparison">Performance Comparison</h2>
<p>To see the impact of false sharing clearly, we can benchmark different versions:</p>
<pre><code class="language-go">package main

import (
    &quot;fmt&quot;
    &quot;sync&quot;
    &quot;sync/atomic&quot;
    &quot;time&quot;
)

// Version with false sharing
func benchmarkFalseSharing() time.Duration {
    start := time.Now()
    
    wg := sync.WaitGroup{}
    wg.Add(2)
    
    var a, b int64
    
    go func() {
        for i := 0; i &lt; 10000000; i++ {
            atomic.AddInt64(&amp;a, 1)
        }
        wg.Done()
    }()
    
    go func() {
        for i := 0; i &lt; 10000000; i++ {
            atomic.AddInt64(&amp;b, 1)
        }
        wg.Done()
    }()
    
    wg.Wait()
    return time.Since(start)
}

// Version avoiding false sharing with padding
type PaddedCounter struct {
    value int64
    _     [56]byte
}

func benchmarkWithPadding() time.Duration {
    start := time.Now()
    
    wg := sync.WaitGroup{}
    wg.Add(2)
    
    var counters [2]PaddedCounter
    
    go func() {
        for i := 0; i &lt; 10000000; i++ {
            atomic.AddInt64(&amp;counters[0].value, 1)
        }
        wg.Done()
    }()
    
    go func() {
        for i := 0; i &lt; 10000000; i++ {
            atomic.AddInt64(&amp;counters[1].value, 1)
        }
        wg.Done()
    }()
    
    wg.Wait()
    return time.Since(start)
}

func main() {
    fmt.Println(&quot;False Sharing Performance Test:&quot;)
    
    falseShareTime := benchmarkFalseSharing()
    fmt.Printf(&quot;With false sharing: %v\n&quot;, falseShareTime)
    
    paddedTime := benchmarkWithPadding()
    fmt.Printf(&quot;Avoiding false sharing: %v\n&quot;, paddedTime)
    
    improvement := float64(falseShareTime) / float64(paddedTime)
    fmt.Printf(&quot;Improvement: %.2fx\n&quot;, improvement)
}
</code></pre>
<p>Output:</p>
<pre><code class="language-bash">False Sharing Performance Test:
With false sharing: 421.989625ms
Avoiding false sharing: 172.8225ms
Improvement: 2.44x
</code></pre>
<h2 id="when-to-care-about-false-sharing">When to Care About False Sharing?</h2>
<p>False sharing is typically only a problem when:</p>
<ol>
<li><strong>Multiple CPU cores</strong> are operating on data simultaneously</li>
<li><strong>High write frequency</strong> on different variables</li>
<li><strong>Data located close together</strong> in memory</li>
<li><strong>Performance critical</strong> applications</li>
</ol>
<h2 id="tools-to-detect-false-sharing">Tools to Detect False Sharing</h2>
<h3 id="1-cpu-performance-counters">1. CPU Performance Counters</h3>
<pre><code class="language-bash"># Using perf on Linux
perf stat -e cache-misses,cache-references ./your-program

# Or with Intel VTune
vtune -collect memory-access ./your-program
</code></pre>
<h3 id="2-go-race-detector">2. Go Race Detector</h3>
<p>Although the race detector doesn&rsquo;t directly detect false sharing, it can help find concurrent access issues:</p>
<pre><code class="language-bash">go run -race main.go
</code></pre>
<h2 id="summary">Summary</h2>
<p>False sharing is a subtle performance bottleneck that can significantly slow down multi-threaded applications. Key takeaways:</p>
<ul>
<li><strong>Cache lines</strong> are typically 64 bytes on most modern processors</li>
<li><strong>Padding</strong> can help separate variables into different cache lines</li>
<li><strong>Local variables</strong> minimize shared memory access</li>
<li><strong>Benchmark</strong> to measure actual impact</li>
<li>Only optimize when truly necessary - premature optimization is the root of all evil!</li>
</ul>
<p>Understanding false sharing helps us write more efficient concurrent code and avoid unexpected performance traps.</p>

</main>

<footer>
  

<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script src="/lib/xiee/js/math-code.min.js" defer></script>
<script src="/lib/katex/katex.min.js" defer></script>
<script src="/lib/katex/auto-render.min.js" defer></script>
<script src="/lib/xiee/js/render-katex.js" defer></script>
<script src="/lib/xiee/js/center-img.min.js" defer></script>
  
  <hr />
  © Zettabytes 2025
  
</footer>
</body>

</html>
